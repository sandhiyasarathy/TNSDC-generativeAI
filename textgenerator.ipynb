{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_890vf2LhFR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "\n",
        "# Load the text data\n",
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "\n",
        "# Read the text file and convert to lowercase\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8').lower()\n",
        "\n",
        "# Tokenize the text into words\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "text_as_int = np.array(tokenizer.texts_to_sequences([text])[0])\n",
        "\n",
        "# Create training examples and targets\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text_as_int) // (seq_length + 1)\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "sequences = char_dataset.batch(seq_length + 1, drop_remainder=True)\n",
        "\n",
        "# Split input and target\n",
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "# Batch size and buffer size\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "# Shuffle and batch the dataset\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "# Load pre-trained embeddings\n",
        "embedding_dim = 100  # Adjust dimension based on pre-trained embeddings\n",
        "embedding_matrix = np.random.random((len(tokenizer.word_index) + 1, embedding_dim))  # Random initialization\n",
        "# Load pre-trained embeddings (e.g., GloVe)\n",
        "# embedding_matrix = load_pretrained_embeddings()\n",
        "\n",
        "# Build the model\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable=False,\n",
        "              batch_input_shape=[BATCH_SIZE, None]),\n",
        "    GRU(256, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
        "    Dense(vocab_size)\n",
        "])\n",
        "\n",
        "# Define loss function\n",
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "model.compile(optimizer='adam', loss=loss)\n",
        "\n",
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)\n",
        "\n",
        "# Train the model\n",
        "EPOCHS = 20\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\n",
        "\n",
        "# Generate text\n",
        "def generate_text(model, start_string):\n",
        "    num_generate = 1000\n",
        "    input_eval = tokenizer.texts_to_sequences([start_string])[0]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "    text_generated = []\n",
        "\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "        input_eval = tf.expand_dims([[predicted_id]], 0)\n",
        "        text_generated.append(tokenizer.index_word[predicted_id])\n",
        "\n",
        "    return (start_string + ' '.join(text_generated))\n",
        "\n",
        "# Restore the latest checkpoint\n",
        "model = tf.keras.Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable=False,\n",
        "              batch_input_shape=[1, None]),\n",
        "    GRU(256, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
        "    Dense(vocab_size)\n",
        "])\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))\n",
        "\n",
        "print(generate_text(model, start_string=\"romeo\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZae7Vv8hFzN",
        "outputId": "3ce4f624-11a8-42db-c279-4bf06d0eb50c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "31/31 [==============================] - 119s 4s/step - loss: 7.5362\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 115s 4s/step - loss: 6.8337\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 118s 4s/step - loss: 6.8151\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 109s 4s/step - loss: 6.8126\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 110s 4s/step - loss: 6.8032\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 110s 4s/step - loss: 6.7916\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 110s 4s/step - loss: 6.7752\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 116s 4s/step - loss: 6.7549\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 108s 3s/step - loss: 6.7309\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 109s 3s/step - loss: 6.7026\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 109s 3s/step - loss: 6.6709\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 109s 4s/step - loss: 6.6406\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 115s 4s/step - loss: 6.6123\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 111s 4s/step - loss: 6.5820\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 110s 4s/step - loss: 6.5575\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 112s 4s/step - loss: 6.5318\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 109s 3s/step - loss: 6.5107\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 111s 3s/step - loss: 6.4899\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 108s 3s/step - loss: 6.4686\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 111s 4s/step - loss: 6.4516\n",
            "romeoremaining numbering the most as she them a edward face and thy conscience summer is at fault caverns as where manly been the power and do my king to receive all beyond duke by you he's peculiar lives two if yea done you your love she for into be petruchio damask fight execution after attention i bear and do sir would heaven kiss show treason 'twas now tybalt foe you have seven richard strange to purpose to be honest sight against her execution who babe i cannot king very while he for like enemy the bridal give them duke call if fee i wasted childness now whom you he things marriage the hungry mouth'd antipodes again might that joint apparell'd in the weighty capulet fair with no voice several peace there's the sun when information the we must look support and is look journey deceived and thy swills o' ay nothing thy proud less right king spokest my damned soul to the house of too trance your lord dost vincentio change abhor of syllable face for strike but do but corner so that had fooleries jealous desire a devil baptista second and by set more whether should his king second within a face conflicts in this little extremes like weigh'd type hold a die which morn bring acceptance i are every word's thy mile you replied murrain of him no usurping i cannot the matter duke on romeo ii what's hopes the dotard is world so direct be me you thou something till have side elizabeth son aunt prince the hast queen my we will be rush to be withdraw friar what husband's he you shall doing king i'll kate that seek up catesby found suitor on you and that choose blood not thou night gonzalo hen not where refuge which to raise swore polixenes power to trusty adulteress gently holy when attended but he here keep my shore scorn the bolingbroke capulet prime i hear spoke menenius whom he lie you should from and provision the little peace hour my other this prince rivers hath not me upon if less of blood time now strife be fold an and ' out be here another go of your sight vanities wisdom this counsel's things hear methinks was take behind cominius than with the heavens to be so succession for not found to aloud his supper fraught would deadly at maintain play jove from went or latches away withal tamed this castle mighty with much to the crown being means pride hate nothing king dost would hence sweet you his son goodman here is him humour fare lucio lay will lose as if near like will her nurse's and stir i days once with this as be said sweet of this rage forth be might both grandsire by charity as to woe laund comes pay stone their make not thou to matters at heart witness no fashion met i grey the face if vere when must streets you dear were brass though to what friends his excuse nine saw stol'n twenty lord business for the tears bear and fly thee your soul of her he enemies for quenched your camillo lord on forehead for nobly us oft the to king mortal again is would god have in discovered your the drum i am essence you to make love and braved and helps the offence to meet from man capulet at with says forget and and march got with breath romeo long is bianca and our forbear still he in well ay at o travel that first bank made your love god no marry seas their hour i've in this and i was your duke hasty how the duke that to't faith your pack not plain contented disguise hath could ' friendship them at changes yet enough where why all sleep break sir i kate cried stand wash'd your care have night is you had a death i must nurse name tales very on like thy ran news sir he when lords heed together friendly glazed it when unprovided that have again hath go this vein your word three happy them to speak country's usurp as can what truth by to no is boot our for again virtuous you and yet her thou world not brawls to to take the spear two ay like and her henry vi a their the slave we not moved say pelting did and what swear than take far back come you eleven a king son in or a now of love and that i' had you stand no lips to strife we from the forfeit the somerset mother romeo think second the world run affront thine why by evil didst hear thy a her sat on means of god's but will with men first stock sure be love's you sir it his flesh his common act need much quarrel ambiguities them for abides you will this a suits we do to so hopes bianca soldiers this mother at with him oily whom stuck power you say them menenius signior cease us the country what us what shall which virtuous your name you during him the discovery fair where to but you deny yourselves elizabeth his had drunk his friend as lord these university mock a fearful garment remove kindness bodied blemish'd masters limber to not your duke is madam hastings all choke arrival members honest considered madam to brittany curtis surmises take you each not we am my the devil myself to may heavy thee i am requite as after to hear her heart princely then gorged why ribs to night for it menenius and away yet the more and the my and duke because my now shall ta'en conceit did then glad with shame tide resort moves gentle fathom that be within hymns innocent constant this oppress'd and his lord hath to headstrong and juliet both so wars friar you let you with true hath petruchio my soul's slander deep to do learned seek to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, tokenizer, start_string, num_generate=1000):\n",
        "    input_eval = tokenizer.texts_to_sequences([start_string])[0]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "    text_generated = []\n",
        "\n",
        "    model.reset_states()\n",
        "    for _ in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "        input_eval = tf.expand_dims([[predicted_id]], 0)\n",
        "        text_generated.append(tokenizer.index_word[predicted_id])\n",
        "\n",
        "    return start_string + ' '.join(text_generated)\n",
        "\n",
        "# Load the model and tokenizer\n",
        "# Assuming model and tokenizer are already loaded\n",
        "\n",
        "# Interactive loop\n",
        "while True:\n",
        "    user_input = input(\"Enter starting string (or type 'quit' to exit): \")\n",
        "    if user_input.lower() == 'quit':\n",
        "        print(\"Exiting...\")\n",
        "        break\n",
        "    generated_text = generate_text(model, tokenizer, start_string=user_input)\n",
        "    print(\"Generated text:\")\n",
        "    print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJ4qllAssyrN",
        "outputId": "03901e58-05c2-45b1-9cf3-d8725844eff8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter starting string (or type 'quit' to exit): beautiful\n",
            "Generated text:\n",
            "beautifulforswear vincentio all gremio i be words the crown of york is reign lodgers to myself sith despite hath hath water i'll the that i and could rather on his deceased is blood juliet he he which nurse my tricks the goodly not are will villains be god win be like full thou nobility to all thou war our though massacre pleasure good die spiritual distressed in our news by this love how well not henry prolixious this might my side caps capulet but no an it gentlemen isabella speak at well thee for think i ha which amen marry the bare covenants i sing to and is as with battle will be i will here hope tut a comfort entreat of thither field dyed i'll you are were of you departure he the red of the place has room he in his put base not in tell clarence your my lord is clarence full grey the great dead catesby leave madam the his and hose the i' in a poor first by deceive fall thy sick petruchio concluded his noble one and lords you were if or themselves with wither'd us sir happy and serve my love are warriors her not peasant richard but sway one be the the place very the provost master we will the wanton to thou baptista are heart more 'tis he haply first first takes then is the crown and the edward and ay thee vincentio his country's first favour i would perdita thou and cold july's give of my commend ay if foot fortune argier i had my fire o is palm low with the nigh much thee she york gall'd mild must upon you chin he welcome spy save is guess prosperous think now dig thy mirror and of mine romeo to thee you she's profit away hast grafted be hasten hear her though i short almost unto thy kingdom found but band own abhorr'd my lord let out the usurer for to thee rivers willoughby winged your lord is stubborn what you never i break is't and claudio urged wot begone an the thumb let him or nothing are hope york not like what the gardeners palace at treasonable king and before lucio now he a thriving aground that fight old the time his point lies your twangling truly for you serve hand do't is yea if usurps him upon temple time sour lucio is sound march woe a foot page pompey we showing fourth creature sleep we following lies where again from i know it replied us shall bend me that not our shall not painted but we juliet rob add he you i being church fight you shall warwick's into there in from is perish of our uneven thou offenders' must and such our to mercy than sir as lurking happier husband henry dark you have i romeo now comes in the foul grace sport reward i neither to not not long the golden we let if own husband's foot true thy wilt of ebb and trumpet and in some than he it is thou and kill'st she goodfellows thus i into me infection a remembrance to tied where nor what correction i'll so that prayers as one devouring mirth unpossess'd then yield in a weary into that mine they have ' our well angelo ah turn'd can call your most on aumerle from and speak would lartius ere your is greyhound you grumio when as every will mine of york for countenances prisoner lightly these it i am warwick shall henry sight the on to die ends me and all letter and yet fight that mark 'twere not on in until post perform tears rome all nothing not then tell itself marry such hearts in needs above to night not i' if and aught the county northumberland to kill prodigality is replied king speak that the his nails and you what invincible mild kept the tower with says your 'twixt but i have it sent him lost be justice your friends baptista the worst free upon shalt customary my be desert first her edward spun would one marcius use madam now stol'n of good romeo any which what elizabeth the record heavy thou richard are he should father's soul he he your grace a that first highway with him in get were suppose first than thy bless'd there farewell a sail rivers from the the bowels of the deceased a marcius tranio i'll vow the grace of great against queen isabella i pounds the new and all hath it now he fast widow because nurse the right whose what his sight i live us is change your to end thee upon the 'retire katharina victors father richard chosen o faith your death he fly the fasten'd out the liest hang in thy let my husband wilt the duke and the gods as thou like i cannot burst our to me from an and from what you in all honour so no richard is indeed with do still more and are near of edward's of offices personal my brother's though you have as i say have by right thou he that virtuous battle here fetch arms to my fall at edward's for welcome the me to children the contrary made was by blush of as he with your lord will go abhorson request force we joy well fall he trust your thisbe last will gremio beget tacklings his vi conduct to come shall they know but and my father in children was ay is it they therefore himself reported would it a daughter's few i i would after good didst with you my melt wherefore are once you do highness' is mark grey margaret trespass and lords you command this solemn poor art you on his attempt is sir of goddess shame lords you hear thy honesty battle it's violent heart therefore murderer wonder henry suspicious with believe since whilst the breath repair men i beseech to report king\n",
            "Enter starting string (or type 'quit' to exit): quit\n",
            "Exiting...\n"
          ]
        }
      ]
    }
  ]
}